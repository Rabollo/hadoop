
wget -qO- https://get.docker.com/ | sh

for mac and windows boot2dock

basic docker commands:
needs sudo:

docker images
docker ps -a

removing:
docker stop $(docker ps -a -q)
docker rm $(docker ps -a -q)
docker rmi [imagename]

adding local varaiables is important

Creating image:

1. The docker yarn cluster
git clone https://github.com/lresende/docker-yarn-cluster
sudo docker build  -t yarn-cluster .
or 
docker build -t lresende/docker-yarn-cluster:latest
if the build fails

The build node:
docker run -v /Users/piotr:/mnt -i -t -p 8088:8088 -p 50070:50070 -p 50075:50075 --name namenode -h namenode yarn-cluster /etc/bootstrap.sh -bash -namenode
docker run -v /Users/piotr:/mnt -i -t --link namenode:namenode --workdir /usr/local/hadoop yarn-cluster /etc/bootstrap.sh -bash -datanode

or if running from pulled 
docker run -v /Users/piotr:/mnt -i -t -p 8088:8088 -p 50070:50070 -p 50075:50075 --name namenode -h namenode lresende/docker-yarn-cluster /etc/bootstrap.sh -bash -namenode
docker run -v /Users/piotr:/mnt -i -t --link namenode:namenode --workdir /usr/local/hadoopl lresende/docker-yarn-cluster /etc/bootstrap.sh -bash -datanode


for mac:
boot2docker init
boot2docker start
sudo route add -net 172.17.0.0/16 192.168.59.103


checking ip:
docker inspect --format='{{.NetworkSettings.IPAddress}}' namenode
port number 50070


testing:
cd $HADOOP_PREFIX

# add input files
bin/hdfs dfs -mkdir -p /user/root
bin/hdfs dfs -put $HADOOP_PREFIX/etc/hadoop/ input

# run the mapreduce
bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0.jar grep input output 'dfs[a-z.]+'

# check the output
bin/hdfs dfs -cat output/*

Other example:
http://www.michael-noll.com/tutorials/writing-an-hadoop-mapreduce-program-in-python/

use bin/hdfs dfs instead of bin/hadoop dfs

If it fails, restart the computer to reset to dns map and ip addresses


2. Other approach with ambari:

docker pull sequenceiq/ambari:1.7.0
curl -Lo .amb j.mp/docker-ambari-170 && . .amb
amb-deploy-cluster 3

adding own mount to ambari needs to change the ambari-functions like in ambari-fcn2 line 114 /Users/piotr is the path.
It will add to master node, if you want to mount files to nodes you have to probably add to amb-start-node() line 141
and then use the the 
curl -Lo .amb file:///Users/piotr/hadoop/ambari-fcn2  && . .amb
where Users/piotr is the path to file
and then 
amb-deploy-cluster 3

http://blog.sequenceiq.com/blog/2014/12/04/multinode-ambari-1-7-0/

